{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Introducción a los DataFrames**\n",
    "\n",
    "## **Inspeccionando un DataFrame**  \n",
    "\n",
    "Cuando trabajas con un nuevo **DataFrame**, lo primero que debes hacer es explorarlo para entender qué información contiene. Para ello, existen varios métodos y atributos útiles en Pandas:  \n",
    "\n",
    "- **`.head()`**: Devuelve las primeras filas del DataFrame (la \"cabeza\" del DataFrame).  \n",
    "- **`.info()`**: Muestra información sobre cada columna, como el tipo de dato y la cantidad de valores faltantes.  \n",
    "- **`.shape`**: Retorna el número de filas y columnas del DataFrame.  \n",
    "- **`.describe()`**: Calcula estadísticas resumidas para cada columna.  \n",
    "\n",
    "El **DataFrame `homelessness`** contiene estimaciones sobre la población sin hogar en cada estado de EE. UU. en el año 2018.  \n",
    "\n",
    "- La columna **`individual`** representa el número de personas sin hogar que no forman parte de una familia con niños.  \n",
    "- La columna **`family_members`** representa el número de personas sin hogar que sí forman parte de una familia con niños.  \n",
    "- La columna **`state_pop`** representa la población total del estado.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "homelessness = (pd\n",
    "    .read_csv('../../datasets/homelessness.csv')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimir el encabezado de los datos `homelessness`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>state</th>\n",
       "      <th>individuals</th>\n",
       "      <th>family_members</th>\n",
       "      <th>state_pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>East South Central</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>864.0</td>\n",
       "      <td>4887681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pacific</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>735139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>7259.0</td>\n",
       "      <td>2606.0</td>\n",
       "      <td>7158024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>West South Central</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>2280.0</td>\n",
       "      <td>432.0</td>\n",
       "      <td>3009733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pacific</td>\n",
       "      <td>California</td>\n",
       "      <td>109008.0</td>\n",
       "      <td>20964.0</td>\n",
       "      <td>39461588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               region       state  individuals  family_members  state_pop\n",
       "0  East South Central     Alabama       2570.0           864.0    4887681\n",
       "1             Pacific      Alaska       1434.0           582.0     735139\n",
       "2            Mountain     Arizona       7259.0          2606.0    7158024\n",
       "3  West South Central    Arkansas       2280.0           432.0    3009733\n",
       "4             Pacific  California     109008.0         20964.0   39461588"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    homelessness\n",
    "    .head()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Imprimir el número de filas y columnas en `homelessness`**  \n",
    "\n",
    "Imprime información sobre los tipos de columnas y los valores faltantes en el DataFrame `homelessness`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51 entries, 0 to 50\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   region          51 non-null     object \n",
      " 1   state           51 non-null     object \n",
      " 2   individuals     51 non-null     float64\n",
      " 3   family_members  51 non-null     float64\n",
      " 4   state_pop       51 non-null     int64  \n",
      "dtypes: float64(2), int64(1), object(2)\n",
      "memory usage: 2.1+ KB\n"
     ]
    }
   ],
   "source": [
    "( \n",
    "    homelessness\n",
    "    .info()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muestra la cantidad de filas y columnas en el DataFrame `homelessness`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    homelessness\n",
    "    .shape\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Imprimir estadísticas resumidas del DataFrame `homelessness`**  \n",
    "\n",
    "Muestra algunas estadísticas descriptivas que resumen los datos en el DataFrame `homelessness`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>individuals</th>\n",
       "      <th>family_members</th>\n",
       "      <th>state_pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>5.100000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7225.784314</td>\n",
       "      <td>3504.882353</td>\n",
       "      <td>6.405637e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15991.025083</td>\n",
       "      <td>7805.411811</td>\n",
       "      <td>7.327258e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>434.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>5.776010e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1446.500000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>1.777414e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3082.000000</td>\n",
       "      <td>1482.000000</td>\n",
       "      <td>4.461153e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6781.500000</td>\n",
       "      <td>3196.000000</td>\n",
       "      <td>7.340946e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>109008.000000</td>\n",
       "      <td>52070.000000</td>\n",
       "      <td>3.946159e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         individuals  family_members     state_pop\n",
       "count      51.000000       51.000000  5.100000e+01\n",
       "mean     7225.784314     3504.882353  6.405637e+06\n",
       "std     15991.025083     7805.411811  7.327258e+06\n",
       "min       434.000000       75.000000  5.776010e+05\n",
       "25%      1446.500000      592.000000  1.777414e+06\n",
       "50%      3082.000000     1482.000000  4.461153e+06\n",
       "75%      6781.500000     3196.000000  7.340946e+06\n",
       "max    109008.000000    52070.000000  3.946159e+07"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "(\n",
    "    homelessness\n",
    "    .describe()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Partes de un DataFrame**  \n",
    "\n",
    "Para comprender mejor los objetos **DataFrame**, es útil saber que están compuestos por tres elementos principales, almacenados como atributos:  \n",
    "\n",
    "- **`.values`**: Un array bidimensional de NumPy que contiene los valores.  \n",
    "- **`.columns`**: Un índice de columnas que almacena los nombres de las columnas.  \n",
    "- **`.index`**: Un índice para las filas, que puede ser una numeración de filas o nombres de filas.  \n",
    "\n",
    "Por lo general, puedes pensar en los **índices** como una lista de cadenas o números, aunque el tipo de dato **Index de Pandas** permite opciones más avanzadas. (Estos conceptos se explicarán más adelante en el curso).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Explorar los atributos de `homelessness`**  \n",
    "\n",
    "1. **Imprimir un array bidimensional de NumPy** con los valores en `homelessness`.  \n",
    "2. **Imprimir los nombres de las columnas** en `homelessness`.  \n",
    "3. **Imprimir el índice** del DataFrame `homelessness`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['East South Central', 'Alabama', 2570.0, 864.0, 4887681],\n",
       "       ['Pacific', 'Alaska', 1434.0, 582.0, 735139],\n",
       "       ['Mountain', 'Arizona', 7259.0, 2606.0, 7158024],\n",
       "       ['West South Central', 'Arkansas', 2280.0, 432.0, 3009733],\n",
       "       ['Pacific', 'California', 109008.0, 20964.0, 39461588],\n",
       "       ['Mountain', 'Colorado', 7607.0, 3250.0, 5691287],\n",
       "       ['New England', 'Connecticut', 2280.0, 1696.0, 3571520],\n",
       "       ['South Atlantic', 'Delaware', 708.0, 374.0, 965479],\n",
       "       ['South Atlantic', 'District of Columbia', 3770.0, 3134.0, 701547],\n",
       "       ['South Atlantic', 'Florida', 21443.0, 9587.0, 21244317],\n",
       "       ['South Atlantic', 'Georgia', 6943.0, 2556.0, 10511131],\n",
       "       ['Pacific', 'Hawaii', 4131.0, 2399.0, 1420593],\n",
       "       ['Mountain', 'Idaho', 1297.0, 715.0, 1750536],\n",
       "       ['East North Central', 'Illinois', 6752.0, 3891.0, 12723071],\n",
       "       ['East North Central', 'Indiana', 3776.0, 1482.0, 6695497],\n",
       "       ['West North Central', 'Iowa', 1711.0, 1038.0, 3148618],\n",
       "       ['West North Central', 'Kansas', 1443.0, 773.0, 2911359],\n",
       "       ['East South Central', 'Kentucky', 2735.0, 953.0, 4461153],\n",
       "       ['West South Central', 'Louisiana', 2540.0, 519.0, 4659690],\n",
       "       ['New England', 'Maine', 1450.0, 1066.0, 1339057],\n",
       "       ['South Atlantic', 'Maryland', 4914.0, 2230.0, 6035802],\n",
       "       ['New England', 'Massachusetts', 6811.0, 13257.0, 6882635],\n",
       "       ['East North Central', 'Michigan', 5209.0, 3142.0, 9984072],\n",
       "       ['West North Central', 'Minnesota', 3993.0, 3250.0, 5606249],\n",
       "       ['East South Central', 'Mississippi', 1024.0, 328.0, 2981020],\n",
       "       ['West North Central', 'Missouri', 3776.0, 2107.0, 6121623],\n",
       "       ['Mountain', 'Montana', 983.0, 422.0, 1060665],\n",
       "       ['West North Central', 'Nebraska', 1745.0, 676.0, 1925614],\n",
       "       ['Mountain', 'Nevada', 7058.0, 486.0, 3027341],\n",
       "       ['New England', 'New Hampshire', 835.0, 615.0, 1353465],\n",
       "       ['Mid-Atlantic', 'New Jersey', 6048.0, 3350.0, 8886025],\n",
       "       ['Mountain', 'New Mexico', 1949.0, 602.0, 2092741],\n",
       "       ['Mid-Atlantic', 'New York', 39827.0, 52070.0, 19530351],\n",
       "       ['South Atlantic', 'North Carolina', 6451.0, 2817.0, 10381615],\n",
       "       ['West North Central', 'North Dakota', 467.0, 75.0, 758080],\n",
       "       ['East North Central', 'Ohio', 6929.0, 3320.0, 11676341],\n",
       "       ['West South Central', 'Oklahoma', 2823.0, 1048.0, 3940235],\n",
       "       ['Pacific', 'Oregon', 11139.0, 3337.0, 4181886],\n",
       "       ['Mid-Atlantic', 'Pennsylvania', 8163.0, 5349.0, 12800922],\n",
       "       ['New England', 'Rhode Island', 747.0, 354.0, 1058287],\n",
       "       ['South Atlantic', 'South Carolina', 3082.0, 851.0, 5084156],\n",
       "       ['West North Central', 'South Dakota', 836.0, 323.0, 878698],\n",
       "       ['East South Central', 'Tennessee', 6139.0, 1744.0, 6771631],\n",
       "       ['West South Central', 'Texas', 19199.0, 6111.0, 28628666],\n",
       "       ['Mountain', 'Utah', 1904.0, 972.0, 3153550],\n",
       "       ['New England', 'Vermont', 780.0, 511.0, 624358],\n",
       "       ['South Atlantic', 'Virginia', 3928.0, 2047.0, 8501286],\n",
       "       ['Pacific', 'Washington', 16424.0, 5880.0, 7523869],\n",
       "       ['South Atlantic', 'West Virginia', 1021.0, 222.0, 1804291],\n",
       "       ['East North Central', 'Wisconsin', 2740.0, 2167.0, 5807406],\n",
       "       ['Mountain', 'Wyoming', 434.0, 205.0, 577601]], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    homelessness\n",
    "    .values\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['region', 'state', 'individuals', 'family_members', 'state_pop'], dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    homelessness\n",
    "    .columns\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=51, step=1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    homelessness\n",
    "    .index\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Ordenamiento y filtrado**\n",
    "\n",
    "## **Ordenar filas**\n",
    "\n",
    "Encontrar información relevante en un **DataFrame** suele ser más fácil si cambiamos el orden de las filas. Puedes ordenarlas utilizando el método `.sort_values()`, pasando el nombre de la columna como argumento.  \n",
    "\n",
    "En casos donde varias filas tienen el mismo valor en la columna de ordenamiento (situación común en variables categóricas), puedes **desempatar** ordenando por otra columna adicional. Para ello, simplemente pasa una lista de nombres de columnas a `.sort_values()`.  \n",
    "\n",
    "| Ordenar por… | Sintaxis |\n",
    "| --- | --- |\n",
    "| Una columna | `df.sort_values(\"breed\")` |\n",
    "| Varias columnas | `df.sort_values([\"breed\", \"weight_kg\"])` |\n",
    "\n",
    "Combinando `.sort_values()` con `.head()`, puedes responder preguntas del tipo:  \n",
    "**\"¿Cuáles son los principales casos en los que…?\"**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ordenar `homelessness` por el número de personas sin hogar**\n",
    "\n",
    "1. Ordena el DataFrame `homelessness` por el número de personas sin hogar (`individual`), de menor a mayor, y guarda el resultado en `homelessness_ind`.  \n",
    "2. Imprime las primeras filas del DataFrame ordenado utilizando `.head()`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>state</th>\n",
       "      <th>individuals</th>\n",
       "      <th>family_members</th>\n",
       "      <th>state_pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Mountain</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>434.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>577601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>West North Central</td>\n",
       "      <td>North Dakota</td>\n",
       "      <td>467.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>758080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>Delaware</td>\n",
       "      <td>708.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>965479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>New England</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>747.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>1058287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>New England</td>\n",
       "      <td>Vermont</td>\n",
       "      <td>780.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>624358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                region         state  individuals  family_members  state_pop\n",
       "50            Mountain       Wyoming        434.0           205.0     577601\n",
       "34  West North Central  North Dakota        467.0            75.0     758080\n",
       "7       South Atlantic      Delaware        708.0           374.0     965479\n",
       "39         New England  Rhode Island        747.0           354.0    1058287\n",
       "45         New England       Vermont        780.0           511.0     624358"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homelessness_ind = (\n",
    "    homelessness\n",
    "    .sort_values('individuals')\n",
    ")\n",
    "\n",
    "print(homelessness_ind.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ordenar `homelessness` por el número de miembros de familias sin hogar**\n",
    "\n",
    "1. Ordena el DataFrame `homelessness` por el número de **miembros de familias sin hogar** (`family_members`) en **orden descendente** y guarda el resultado en `homelessness_fam`.  \n",
    "2. Imprime las primeras filas del DataFrame ordenado utilizando `.head()`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>state</th>\n",
       "      <th>individuals</th>\n",
       "      <th>family_members</th>\n",
       "      <th>state_pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Mid-Atlantic</td>\n",
       "      <td>New York</td>\n",
       "      <td>39827.0</td>\n",
       "      <td>52070.0</td>\n",
       "      <td>19530351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pacific</td>\n",
       "      <td>California</td>\n",
       "      <td>109008.0</td>\n",
       "      <td>20964.0</td>\n",
       "      <td>39461588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>New England</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>6811.0</td>\n",
       "      <td>13257.0</td>\n",
       "      <td>6882635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>Florida</td>\n",
       "      <td>21443.0</td>\n",
       "      <td>9587.0</td>\n",
       "      <td>21244317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>West South Central</td>\n",
       "      <td>Texas</td>\n",
       "      <td>19199.0</td>\n",
       "      <td>6111.0</td>\n",
       "      <td>28628666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                region          state  individuals  family_members  state_pop\n",
       "32        Mid-Atlantic       New York      39827.0         52070.0   19530351\n",
       "4              Pacific     California     109008.0         20964.0   39461588\n",
       "21         New England  Massachusetts       6811.0         13257.0    6882635\n",
       "9       South Atlantic        Florida      21443.0          9587.0   21244317\n",
       "43  West South Central          Texas      19199.0          6111.0   28628666"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homelessness_fam = (\n",
    "    homelessness\n",
    "    .sort_values(\n",
    "        'family_members', \n",
    "        ascending=False\n",
    "    )\n",
    ")\n",
    "\n",
    "print(homelessness_fam.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ordenar `homelessness` por región y número de miembros de familias sin hogar**\n",
    "\n",
    "1. Ordena el DataFrame `homelessness` primero por **región** en **orden ascendente**, y luego por el número de **miembros de familias sin hogar** (`family_members`) en **orden descendente**.  \n",
    "2. Guarda el resultado en `homelessness_reg_fam`.  \n",
    "3. Imprime las primeras filas del DataFrame ordenado utilizando `.head()`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                region      state  individuals  family_members  state_pop\n",
      "13  East North Central   Illinois       6752.0          3891.0   12723071\n",
      "35  East North Central       Ohio       6929.0          3320.0   11676341\n",
      "22  East North Central   Michigan       5209.0          3142.0    9984072\n",
      "49  East North Central  Wisconsin       2740.0          2167.0    5807406\n",
      "14  East North Central    Indiana       3776.0          1482.0    6695497\n"
     ]
    }
   ],
   "source": [
    "homelessness_reg_fam = (\n",
    "    homelessness\n",
    "    .sort_values(\n",
    "        ['region', 'family_members'], \n",
    "        ascending=[True, False]\n",
    "    )\n",
    ")\n",
    "\n",
    "print(homelessness_reg_fam.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí tienes la traducción en formato Markdown:\n",
    "\n",
    "# **Filtrado de columnas**\n",
    "\n",
    "Al trabajar con datos, es posible que no necesites todas las variables de tu conjunto de datos. Puedes utilizar corchetes (`[]`) para seleccionar únicamente las columnas que te interesan, en el orden que prefieras.  \n",
    "\n",
    "Para seleccionar solo la columna `\"col_a\"` del DataFrame `df`, usa:  \n",
    "\n",
    "```python\n",
    "df[\"col_a\"]\n",
    "\n",
    "Para seleccionar las columnas \"col_a\" y \"col_b\" de df, usa:\n",
    "\n",
    "df[[\"col_a\", \"col_b\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Seleccionar la columna `individuals` del DataFrame `homelessness`**\n",
    "\n",
    "1. Crea un nuevo DataFrame llamado `individuals` que contenga solo la columna `individuals` del DataFrame `homelessness`.  \n",
    "2. Imprime las primeras filas del resultado utilizando `.head()`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   individuals\n",
      "0       2570.0\n",
      "1       1434.0\n",
      "2       7259.0\n",
      "3       2280.0\n",
      "4     109008.0\n"
     ]
    }
   ],
   "source": [
    "individuals = (\n",
    "    homelessness[['individuals']]\n",
    ")\n",
    "\n",
    "print(individuals.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Seleccionar las columnas `state` y `family_members` del DataFrame `homelessness`**\n",
    "\n",
    "1. Crea un nuevo DataFrame llamado `state_fam` que contenga únicamente las columnas `state` y `family_members` del DataFrame `homelessness`, en ese orden.  \n",
    "2. Imprime las primeras filas del resultado utilizando `.head()`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        state  family_members\n",
      "0     Alabama           864.0\n",
      "1      Alaska           582.0\n",
      "2     Arizona          2606.0\n",
      "3    Arkansas           432.0\n",
      "4  California         20964.0\n"
     ]
    }
   ],
   "source": [
    "state_fam = (\n",
    "    homelessness[['state', 'family_members']]\n",
    ")\n",
    "\n",
    "print(state_fam.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Seleccionar las columnas `individuals` y `state` del DataFrame `homelessness`**\n",
    "\n",
    "1. Crea un nuevo DataFrame llamado `ind_state` que contenga únicamente las columnas `individuals` y `state` del DataFrame `homelessness`, en ese orden.  \n",
    "2. Imprime las primeras filas del resultado utilizando `.head()`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   individuals       state\n",
      "0       2570.0     Alabama\n",
      "1       1434.0      Alaska\n",
      "2       7259.0     Arizona\n",
      "3       2280.0    Arkansas\n",
      "4     109008.0  California\n"
     ]
    }
   ],
   "source": [
    "ind_state = (\n",
    "    homelessness[\n",
    "        [\n",
    "            'individuals', \n",
    "            'state'\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(ind_state.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Filtrado de filas (Subsetting rows)**  \n",
    "\n",
    "Una gran parte de la ciencia de datos consiste en identificar qué partes del conjunto de datos son **interesantes**. Una de las técnicas más simples para esto es encontrar un **subconjunto de filas** que cumplan con ciertos criterios. A este proceso también se le conoce como **filtrado de filas** o **selección de filas**.  \n",
    "\n",
    "Existen varias formas de filtrar un DataFrame, pero la más común es utilizar **operadores relacionales** para obtener valores `True` o `False` para cada fila, y luego pasar este resultado dentro de corchetes (`[]`).  \n",
    "\n",
    "```python\n",
    "dogs[dogs[\"height_cm\"] > 60]\n",
    "dogs[dogs[\"color\"] == \"tan\"]\n",
    "\n",
    "Si deseas filtrar múltiples condiciones al mismo tiempo, puedes utilizar el operador “bitwise and” (&):\n",
    "\n",
    "dogs[(dogs[\"height_cm\"] > 60) & (dogs[\"color\"] == \"tan\")]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Filtrar `homelessness` para casos con más de 10,000 individuos sin hogar**  \n",
    "\n",
    "1. Filtra el DataFrame `homelessness` para incluir solo los casos donde la columna `individuals` sea **mayor a 10,000**.  \n",
    "2. Guarda el resultado en un nuevo DataFrame llamado `ind_gt_10k`.  \n",
    "3. Imprime el resultado para visualizar los datos filtrados.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                region       state  individuals  family_members  state_pop\n",
      "4              Pacific  California     109008.0         20964.0   39461588\n",
      "9       South Atlantic     Florida      21443.0          9587.0   21244317\n",
      "32        Mid-Atlantic    New York      39827.0         52070.0   19530351\n",
      "37             Pacific      Oregon      11139.0          3337.0    4181886\n",
      "43  West South Central       Texas      19199.0          6111.0   28628666\n",
      "47             Pacific  Washington      16424.0          5880.0    7523869\n"
     ]
    }
   ],
   "source": [
    "ind_gt_10k = (\n",
    "    homelessness[homelessness['individuals'] > 10000]\n",
    ")\n",
    "\n",
    "print(ind_gt_10k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Filtrar `homelessness` para la región del censo de EE. UU. `\"Mountain\"`**  \n",
    "\n",
    "1. Filtra el DataFrame `homelessness` para incluir solo los casos donde la columna `region` sea `\"Mountain\"`.  \n",
    "2. Guarda el resultado en un nuevo DataFrame llamado `mountain_reg`.  \n",
    "3. Imprime el resultado para visualizar los datos filtrados.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      region       state  individuals  family_members  state_pop\n",
      "2   Mountain     Arizona       7259.0          2606.0    7158024\n",
      "5   Mountain    Colorado       7607.0          3250.0    5691287\n",
      "12  Mountain       Idaho       1297.0           715.0    1750536\n",
      "26  Mountain     Montana        983.0           422.0    1060665\n",
      "28  Mountain      Nevada       7058.0           486.0    3027341\n",
      "31  Mountain  New Mexico       1949.0           602.0    2092741\n",
      "44  Mountain        Utah       1904.0           972.0    3153550\n",
      "50  Mountain     Wyoming        434.0           205.0     577601\n"
     ]
    }
   ],
   "source": [
    "mountain_reg = (\n",
    "    homelessness[\n",
    "        homelessness['region'] == 'Mountain'\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(mountain_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Filtrar `homelessness` para casos con menos de 1,000 miembros de familia en la región \"Pacific\"**  \n",
    "\n",
    "1. Filtra el DataFrame `homelessness` para incluir solo los casos donde:  \n",
    "   - La columna `family_members` sea **menor a 1,000**.  \n",
    "   - La columna `region` sea **\"Pacific\"**.  \n",
    "2. Guarda el resultado en un nuevo DataFrame llamado `fam_lt_1k_pac`.  \n",
    "3. Imprime el resultado para visualizar los datos filtrados.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    region   state  individuals  family_members  state_pop\n",
      "1  Pacific  Alaska       1434.0           582.0     735139\n"
     ]
    }
   ],
   "source": [
    "fam_lt_1k_pac = (\n",
    "    homelessness[(homelessness['family_members'] < 1000) & (homelessness['region'] == 'Pacific')]\n",
    ")\n",
    "\n",
    "print(fam_lt_1k_pac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Filtrado de filas por variables categóricas**\n",
    "\n",
    "Filtrar datos basados en una variable categórica a menudo implica usar el operador **\"or\"** (`|`) para seleccionar filas de múltiples categorías. Sin embargo, esto puede volverse tedioso cuando deseas incluir varias categorías al mismo tiempo.  \n",
    "\n",
    "Para simplificar el proceso, puedes utilizar el método `.isin()`, el cual permite aplicar una única condición en lugar de escribir varias condiciones separadas.  \n",
    "\n",
    "```python\n",
    "colors = [\"brown\", \"black\", \"tan\"]\n",
    "condition = dogs[\"color\"].isin(colors)\n",
    "dogs[condition]\n",
    "\n",
    "Esto seleccionará todas las filas donde la columna \"color\" tenga uno de los valores en la lista [\"brown\", \"black\", \"tan\"]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Filtrar `homelessness` para las regiones \"South Atlantic\" o \"Mid-Atlantic\"**  \n",
    "\n",
    "1. Filtra el DataFrame `homelessness` para incluir solo los casos donde la columna `region` sea **\"South Atlantic\"** o **\"Mid-Atlantic\"**.  \n",
    "2. Guarda el resultado en un nuevo DataFrame llamado `south_mid_atlantic`.  \n",
    "3. Imprime el resultado para visualizar los datos filtrados.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            region                 state  individuals  family_members  \\\n",
      "7   South Atlantic              Delaware        708.0           374.0   \n",
      "8   South Atlantic  District of Columbia       3770.0          3134.0   \n",
      "9   South Atlantic               Florida      21443.0          9587.0   \n",
      "10  South Atlantic               Georgia       6943.0          2556.0   \n",
      "20  South Atlantic              Maryland       4914.0          2230.0   \n",
      "30    Mid-Atlantic            New Jersey       6048.0          3350.0   \n",
      "32    Mid-Atlantic              New York      39827.0         52070.0   \n",
      "33  South Atlantic        North Carolina       6451.0          2817.0   \n",
      "38    Mid-Atlantic          Pennsylvania       8163.0          5349.0   \n",
      "40  South Atlantic        South Carolina       3082.0           851.0   \n",
      "46  South Atlantic              Virginia       3928.0          2047.0   \n",
      "48  South Atlantic         West Virginia       1021.0           222.0   \n",
      "\n",
      "    state_pop  \n",
      "7      965479  \n",
      "8      701547  \n",
      "9    21244317  \n",
      "10   10511131  \n",
      "20    6035802  \n",
      "30    8886025  \n",
      "32   19530351  \n",
      "33   10381615  \n",
      "38   12800922  \n",
      "40    5084156  \n",
      "46    8501286  \n",
      "48    1804291  \n"
     ]
    }
   ],
   "source": [
    "south_mid_atlantic = (\n",
    "    homelessness[(homelessness['region'] == 'South Atlantic') | (homelessness['region'] == 'Mid-Atlantic')]\n",
    ")\n",
    "\n",
    "print(south_mid_atlantic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Filtrar `homelessness` para los estados de Mojave (`canu`)**  \n",
    "\n",
    "1. Filtra el DataFrame `homelessness` para incluir solo los casos donde la columna `state` esté en la lista de **estados de Mojave**, denominada `canu`.  \n",
    "2. Guarda el resultado en un nuevo DataFrame llamado `mojave_homelessness`.  \n",
    "3. Imprime el resultado para visualizar los datos filtrados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      region       state  individuals  family_members  state_pop\n",
      "2   Mountain     Arizona       7259.0          2606.0    7158024\n",
      "4    Pacific  California     109008.0         20964.0   39461588\n",
      "28  Mountain      Nevada       7058.0           486.0    3027341\n",
      "44  Mountain        Utah       1904.0           972.0    3153550\n"
     ]
    }
   ],
   "source": [
    "canu = [\"California\", \"Arizona\", \"Nevada\", \"Utah\"]\n",
    "\n",
    "mojave_homelessness = (\n",
    "    homelessness[homelessness['state'].isin(canu)]\n",
    ")\n",
    "\n",
    "print(mojave_homelessness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Agregar nuevas columnas**\n",
    "\n",
    "No estás limitado a los datos que te proporcionan. En su lugar, puedes agregar nuevas columnas a un **DataFrame**. Este proceso tiene varios nombres, como **transformación**, **mutación** y **ingeniería de características (feature engineering)**.  \n",
    "\n",
    "Puedes crear nuevas columnas desde cero, pero también es común derivarlas a partir de otras columnas, por ejemplo, sumando valores de diferentes columnas o cambiando sus unidades.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Agregar nuevas columnas a `homelessness`**  \n",
    "\n",
    "1. **Agregar una nueva columna llamada `total`**  \n",
    "   - Contendrá la suma de las columnas `individuals` y `family_members`, representando el total de personas sin hogar en cada estado.  \n",
    "\n",
    "2. **Agregar otra columna llamada `p_individuals`**  \n",
    "   - Contendrá la proporción de personas sin hogar que son individuos, calculada como:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                region                 state  individuals  family_members  \\\n",
      "0   East South Central               Alabama       2570.0           864.0   \n",
      "1              Pacific                Alaska       1434.0           582.0   \n",
      "2             Mountain               Arizona       7259.0          2606.0   \n",
      "3   West South Central              Arkansas       2280.0           432.0   \n",
      "4              Pacific            California     109008.0         20964.0   \n",
      "5             Mountain              Colorado       7607.0          3250.0   \n",
      "6          New England           Connecticut       2280.0          1696.0   \n",
      "7       South Atlantic              Delaware        708.0           374.0   \n",
      "8       South Atlantic  District of Columbia       3770.0          3134.0   \n",
      "9       South Atlantic               Florida      21443.0          9587.0   \n",
      "10      South Atlantic               Georgia       6943.0          2556.0   \n",
      "11             Pacific                Hawaii       4131.0          2399.0   \n",
      "12            Mountain                 Idaho       1297.0           715.0   \n",
      "13  East North Central              Illinois       6752.0          3891.0   \n",
      "14  East North Central               Indiana       3776.0          1482.0   \n",
      "15  West North Central                  Iowa       1711.0          1038.0   \n",
      "16  West North Central                Kansas       1443.0           773.0   \n",
      "17  East South Central              Kentucky       2735.0           953.0   \n",
      "18  West South Central             Louisiana       2540.0           519.0   \n",
      "19         New England                 Maine       1450.0          1066.0   \n",
      "20      South Atlantic              Maryland       4914.0          2230.0   \n",
      "21         New England         Massachusetts       6811.0         13257.0   \n",
      "22  East North Central              Michigan       5209.0          3142.0   \n",
      "23  West North Central             Minnesota       3993.0          3250.0   \n",
      "24  East South Central           Mississippi       1024.0           328.0   \n",
      "25  West North Central              Missouri       3776.0          2107.0   \n",
      "26            Mountain               Montana        983.0           422.0   \n",
      "27  West North Central              Nebraska       1745.0           676.0   \n",
      "28            Mountain                Nevada       7058.0           486.0   \n",
      "29         New England         New Hampshire        835.0           615.0   \n",
      "30        Mid-Atlantic            New Jersey       6048.0          3350.0   \n",
      "31            Mountain            New Mexico       1949.0           602.0   \n",
      "32        Mid-Atlantic              New York      39827.0         52070.0   \n",
      "33      South Atlantic        North Carolina       6451.0          2817.0   \n",
      "34  West North Central          North Dakota        467.0            75.0   \n",
      "35  East North Central                  Ohio       6929.0          3320.0   \n",
      "36  West South Central              Oklahoma       2823.0          1048.0   \n",
      "37             Pacific                Oregon      11139.0          3337.0   \n",
      "38        Mid-Atlantic          Pennsylvania       8163.0          5349.0   \n",
      "39         New England          Rhode Island        747.0           354.0   \n",
      "40      South Atlantic        South Carolina       3082.0           851.0   \n",
      "41  West North Central          South Dakota        836.0           323.0   \n",
      "42  East South Central             Tennessee       6139.0          1744.0   \n",
      "43  West South Central                 Texas      19199.0          6111.0   \n",
      "44            Mountain                  Utah       1904.0           972.0   \n",
      "45         New England               Vermont        780.0           511.0   \n",
      "46      South Atlantic              Virginia       3928.0          2047.0   \n",
      "47             Pacific            Washington      16424.0          5880.0   \n",
      "48      South Atlantic         West Virginia       1021.0           222.0   \n",
      "49  East North Central             Wisconsin       2740.0          2167.0   \n",
      "50            Mountain               Wyoming        434.0           205.0   \n",
      "\n",
      "    state_pop     total  p_individuals  \n",
      "0     4887681    3434.0       0.748398  \n",
      "1      735139    2016.0       0.711310  \n",
      "2     7158024    9865.0       0.735834  \n",
      "3     3009733    2712.0       0.840708  \n",
      "4    39461588  129972.0       0.838704  \n",
      "5     5691287   10857.0       0.700654  \n",
      "6     3571520    3976.0       0.573441  \n",
      "7      965479    1082.0       0.654344  \n",
      "8      701547    6904.0       0.546060  \n",
      "9    21244317   31030.0       0.691041  \n",
      "10   10511131    9499.0       0.730919  \n",
      "11    1420593    6530.0       0.632619  \n",
      "12    1750536    2012.0       0.644632  \n",
      "13   12723071   10643.0       0.634408  \n",
      "14    6695497    5258.0       0.718144  \n",
      "15    3148618    2749.0       0.622408  \n",
      "16    2911359    2216.0       0.651173  \n",
      "17    4461153    3688.0       0.741594  \n",
      "18    4659690    3059.0       0.830337  \n",
      "19    1339057    2516.0       0.576312  \n",
      "20    6035802    7144.0       0.687850  \n",
      "21    6882635   20068.0       0.339396  \n",
      "22    9984072    8351.0       0.623758  \n",
      "23    5606249    7243.0       0.551291  \n",
      "24    2981020    1352.0       0.757396  \n",
      "25    6121623    5883.0       0.641849  \n",
      "26    1060665    1405.0       0.699644  \n",
      "27    1925614    2421.0       0.720777  \n",
      "28    3027341    7544.0       0.935578  \n",
      "29    1353465    1450.0       0.575862  \n",
      "30    8886025    9398.0       0.643541  \n",
      "31    2092741    2551.0       0.764014  \n",
      "32   19530351   91897.0       0.433387  \n",
      "33   10381615    9268.0       0.696051  \n",
      "34     758080     542.0       0.861624  \n",
      "35   11676341   10249.0       0.676066  \n",
      "36    3940235    3871.0       0.729269  \n",
      "37    4181886   14476.0       0.769481  \n",
      "38   12800922   13512.0       0.604130  \n",
      "39    1058287    1101.0       0.678474  \n",
      "40    5084156    3933.0       0.783626  \n",
      "41     878698    1159.0       0.721311  \n",
      "42    6771631    7883.0       0.778764  \n",
      "43   28628666   25310.0       0.758554  \n",
      "44    3153550    2876.0       0.662031  \n",
      "45     624358    1291.0       0.604183  \n",
      "46    8501286    5975.0       0.657406  \n",
      "47    7523869   22304.0       0.736370  \n",
      "48    1804291    1243.0       0.821400  \n",
      "49    5807406    4907.0       0.558386  \n",
      "50     577601     639.0       0.679186  \n"
     ]
    }
   ],
   "source": [
    "homelessness['total'] = (\n",
    "    homelessness['individuals'] \n",
    "    + homelessness['family_members']\n",
    ")\n",
    "\n",
    "homelessness['p_individuals'] = (\n",
    "    homelessness['individuals'] / homelessness['total']\n",
    ")\n",
    "\n",
    "print(homelessness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Combo-attack!**\n",
    "\n",
    "You've seen the four most common types of data manipulation: sorting rows, subsetting columns, subsetting rows, and adding new columns. In a real-life data analysis, you can mix and match these four manipulations to answer a multitude of questions.\n",
    "\n",
    "In this exercise, you'll answer the question, \"Which state has the highest number of homeless individuals per 10,000 people in the state?\" Combine your new `pandas` skills to find out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add a column to `homelessness`, `indiv_per_10k`, containing the number of homeless individuals per ten thousand people in each state.\n",
    "- Subset rows where `indiv_per_10k` is higher than `20`, assigning to `high_homelessness`.\n",
    "- Sort `high_homelessness` by descending `indiv_per_10k`, assigning to `high_homelessness_srt`.\n",
    "- Select only the `state` and `indiv_per_10k` columns of `high_homelessness_srt` and save as `result`. *Look at the `result`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   state  indiv_per_10k\n",
      "8   District of Columbia      53.738381\n",
      "11                Hawaii      29.079406\n",
      "4             California      27.623825\n",
      "37                Oregon      26.636307\n",
      "28                Nevada      23.314189\n",
      "47            Washington      21.829195\n",
      "32              New York      20.392363\n"
     ]
    }
   ],
   "source": [
    "# Create indiv_per_10k col as homeless individuals per 10k state pop\n",
    "homelessness[\"indiv_per_10k\"] = 10000 * homelessness[\"individuals\"] / homelessness[\"state_pop\"] \n",
    "\n",
    "# Subset rows for indiv_per_10k greater than 20\n",
    "high_homelessness = homelessness[homelessness[\"indiv_per_10k\"] > 20]\n",
    "\n",
    "# Sort high_homelessness by descending indiv_per_10k\n",
    "high_homelessness_srt = high_homelessness.sort_values(\"indiv_per_10k\", ascending=False)\n",
    "\n",
    "# From high_homelessness_srt, select the state and indiv_per_10k cols\n",
    "result = high_homelessness_srt[[\"state\", \"indiv_per_10k\"]]\n",
    "\n",
    "# See the result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Mean and median**\n",
    "\n",
    "Summary statistics are exactly what they sound like - they summarize many numbers in one statistic. For example, mean, median, minimum, maximum, and standard deviation are summary statistics. Calculating summary statistics allows you to get a better sense of your data, even if there's a lot of it.\n",
    "\n",
    "`sales` is available and `pandas` is loaded as `pd`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Explore your new DataFrame first by printing the first few rows of the `sales` DataFrame.\n",
    "- Print information about the columns in `sales`.\n",
    "- Print the mean of the `weekly_sales` column.\n",
    "- Print the median of the `weekly_sales` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>type</th>\n",
       "      <th>department</th>\n",
       "      <th>date</th>\n",
       "      <th>weekly_sales</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>temperature_c</th>\n",
       "      <th>fuel_price_usd_per_l</th>\n",
       "      <th>unemployment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>24924.50</td>\n",
       "      <td>False</td>\n",
       "      <td>5.727778</td>\n",
       "      <td>0.679451</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-03-05</td>\n",
       "      <td>21827.90</td>\n",
       "      <td>False</td>\n",
       "      <td>8.055556</td>\n",
       "      <td>0.693452</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-04-02</td>\n",
       "      <td>57258.43</td>\n",
       "      <td>False</td>\n",
       "      <td>16.816667</td>\n",
       "      <td>0.718284</td>\n",
       "      <td>7.808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-05-07</td>\n",
       "      <td>17413.94</td>\n",
       "      <td>False</td>\n",
       "      <td>22.527778</td>\n",
       "      <td>0.748928</td>\n",
       "      <td>7.808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-06-04</td>\n",
       "      <td>17558.09</td>\n",
       "      <td>False</td>\n",
       "      <td>27.050000</td>\n",
       "      <td>0.714586</td>\n",
       "      <td>7.808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   store type  department        date  weekly_sales  is_holiday  \\\n",
       "0      1    A           1  2010-02-05      24924.50       False   \n",
       "1      1    A           1  2010-03-05      21827.90       False   \n",
       "2      1    A           1  2010-04-02      57258.43       False   \n",
       "3      1    A           1  2010-05-07      17413.94       False   \n",
       "4      1    A           1  2010-06-04      17558.09       False   \n",
       "\n",
       "   temperature_c  fuel_price_usd_per_l  unemployment  \n",
       "0       5.727778              0.679451         8.106  \n",
       "1       8.055556              0.693452         8.106  \n",
       "2      16.816667              0.718284         7.808  \n",
       "3      22.527778              0.748928         7.808  \n",
       "4      27.050000              0.714586         7.808  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales = pd.read_csv('walmart.csv')\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   store type  department        date  weekly_sales  is_holiday  \\\n",
      "0      1    A           1  2010-02-05      24924.50       False   \n",
      "1      1    A           1  2010-03-05      21827.90       False   \n",
      "2      1    A           1  2010-04-02      57258.43       False   \n",
      "3      1    A           1  2010-05-07      17413.94       False   \n",
      "4      1    A           1  2010-06-04      17558.09       False   \n",
      "\n",
      "   temperature_c  fuel_price_usd_per_l  unemployment  \n",
      "0       5.727778              0.679451         8.106  \n",
      "1       8.055556              0.693452         8.106  \n",
      "2      16.816667              0.718284         7.808  \n",
      "3      22.527778              0.748928         7.808  \n",
      "4      27.050000              0.714586         7.808  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10774 entries, 0 to 10773\n",
      "Data columns (total 9 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   store                 10774 non-null  int64  \n",
      " 1   type                  10774 non-null  object \n",
      " 2   department            10774 non-null  int64  \n",
      " 3   date                  10774 non-null  object \n",
      " 4   weekly_sales          10774 non-null  float64\n",
      " 5   is_holiday            10774 non-null  bool   \n",
      " 6   temperature_c         10774 non-null  float64\n",
      " 7   fuel_price_usd_per_l  10774 non-null  float64\n",
      " 8   unemployment          10774 non-null  float64\n",
      "dtypes: bool(1), float64(4), int64(2), object(2)\n",
      "memory usage: 684.0+ KB\n",
      "None\n",
      "23843.95014850566\n",
      "12049.064999999999\n"
     ]
    }
   ],
   "source": [
    "# Print the head of the sales DataFrame\n",
    "print(sales.head())\n",
    "\n",
    "# Print the info about the sales DataFrame\n",
    "print(sales.info())\n",
    "\n",
    "# Print the mean of weekly_sales\n",
    "print(sales['weekly_sales'].mean())\n",
    "\n",
    "# Print the median of weekly_sales\n",
    "print(sales['weekly_sales'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print the maximum of the `date` column.\n",
    "- Print the minimum of the `date` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012-10-26\n",
      "2010-02-05\n"
     ]
    }
   ],
   "source": [
    "# Print the maximum of the date column\n",
    "print(sales['date'].max())\n",
    "\n",
    "# Print the minimum of the date column\n",
    "print(sales['date'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Efficient summaries**\n",
    "\n",
    "While pandas and NumPy have tons of functions, sometimes, you may need a different function to summarize your data.\n",
    "\n",
    "The `.agg()` method allows you to apply your own custom functions to a DataFrame, as well as apply functions to more than one column of a DataFrame at once, making your aggregations super-efficient. For example,\n",
    "\n",
    "```\n",
    "df['column'].agg(function)\n",
    "\n",
    "```\n",
    "\n",
    "In the custom function for this exercise, \"IQR\" is short for inter-quartile range, which is the 75th percentile minus the 25th percentile. It's an alternative to standard deviation that is helpful if your data contains outliers.\n",
    "\n",
    "`sales` is available and `pandas` is loaded as `pd`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use the custom `iqr` function defined for you along with `.agg()` to print the IQR of the `temperature_c` column of `sales`.\n",
    "- Update the column selection to use the custom `iqr` function with `.agg()` to print the IQR of `temperature_c`, `fuel_price_usd_per_l`, and `unemployment`, in that order.\n",
    "- Update the aggregation functions called by `.agg()`: include `iqr` and `np.median` in that order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.583333333333336\n"
     ]
    }
   ],
   "source": [
    "# A custom IQR function\n",
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "    \n",
    "# Print IQR of the temperature_c column\n",
    "print(sales['temperature_c'].agg(iqr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temperature_c           16.583333\n",
      "fuel_price_usd_per_l     0.073176\n",
      "unemployment             0.565000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# A custom IQR function\n",
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "\n",
    "# Update to print IQR of temperature_c, fuel_price_usd_per_l, & unemployment\n",
    "print(sales[[\"temperature_c\", 'fuel_price_usd_per_l', 'unemployment']].agg(iqr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        temperature_c  fuel_price_usd_per_l  unemployment\n",
      "iqr         16.583333              0.073176         0.565\n",
      "median      16.966667              0.743381         8.099\n"
     ]
    }
   ],
   "source": [
    "# Import NumPy and create custom IQR function\n",
    "import numpy as np\n",
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "\n",
    "# Update to print IQR and median of temperature_c, fuel_price_usd_per_l, & unemployment\n",
    "print(sales[[\"temperature_c\", \"fuel_price_usd_per_l\", \"unemployment\"]].agg([iqr, 'median']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Cumulative statistics**\n",
    "\n",
    "Cumulative statistics can also be helpful in tracking summary statistics over time. In this exercise, you'll calculate the cumulative sum and cumulative max of a department's weekly sales, which will allow you to identify what the total sales were so far as well as what the highest weekly sales were so far.\n",
    "\n",
    "A DataFrame called `sales_1_1` has been created for you, which contains the sales data for department 1 of store 1. `pandas` is loaded as `pd`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sort the rows of `sales_1_1` by the `date` column in ascending order.\n",
    "- Get the cumulative sum of `weekly_sales` and add it as a new column of `sales_1_1` called `cum_weekly_sales`.\n",
    "- Get the cumulative maximum of `weekly_sales`, and add it as a column called `cum_max_sales`.\n",
    "- Print the `date`, `weekly_sales`, `cum_weekly_sales`, and `cum_max_sales` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>type</th>\n",
       "      <th>department</th>\n",
       "      <th>date</th>\n",
       "      <th>weekly_sales</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>temperature_c</th>\n",
       "      <th>fuel_price_usd_per_l</th>\n",
       "      <th>unemployment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>24924.50</td>\n",
       "      <td>False</td>\n",
       "      <td>5.727778</td>\n",
       "      <td>0.679451</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-03-05</td>\n",
       "      <td>21827.90</td>\n",
       "      <td>False</td>\n",
       "      <td>8.055556</td>\n",
       "      <td>0.693452</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-04-02</td>\n",
       "      <td>57258.43</td>\n",
       "      <td>False</td>\n",
       "      <td>16.816667</td>\n",
       "      <td>0.718284</td>\n",
       "      <td>7.808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-05-07</td>\n",
       "      <td>17413.94</td>\n",
       "      <td>False</td>\n",
       "      <td>22.527778</td>\n",
       "      <td>0.748928</td>\n",
       "      <td>7.808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-06-04</td>\n",
       "      <td>17558.09</td>\n",
       "      <td>False</td>\n",
       "      <td>27.050000</td>\n",
       "      <td>0.714586</td>\n",
       "      <td>7.808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-07-02</td>\n",
       "      <td>16333.14</td>\n",
       "      <td>False</td>\n",
       "      <td>27.172222</td>\n",
       "      <td>0.705076</td>\n",
       "      <td>7.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-08-06</td>\n",
       "      <td>17508.41</td>\n",
       "      <td>False</td>\n",
       "      <td>30.644444</td>\n",
       "      <td>0.693980</td>\n",
       "      <td>7.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-09-03</td>\n",
       "      <td>16241.78</td>\n",
       "      <td>False</td>\n",
       "      <td>27.338889</td>\n",
       "      <td>0.680772</td>\n",
       "      <td>7.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-10-01</td>\n",
       "      <td>20094.19</td>\n",
       "      <td>False</td>\n",
       "      <td>22.161111</td>\n",
       "      <td>0.687640</td>\n",
       "      <td>7.838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-11-05</td>\n",
       "      <td>34238.88</td>\n",
       "      <td>False</td>\n",
       "      <td>14.855556</td>\n",
       "      <td>0.710359</td>\n",
       "      <td>7.838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-12-03</td>\n",
       "      <td>22517.56</td>\n",
       "      <td>False</td>\n",
       "      <td>9.594444</td>\n",
       "      <td>0.715378</td>\n",
       "      <td>7.838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-07</td>\n",
       "      <td>15984.24</td>\n",
       "      <td>False</td>\n",
       "      <td>9.038889</td>\n",
       "      <td>0.786176</td>\n",
       "      <td>7.742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    store type  department        date  weekly_sales  is_holiday  \\\n",
       "0       1    A           1  2010-02-05      24924.50       False   \n",
       "1       1    A           1  2010-03-05      21827.90       False   \n",
       "2       1    A           1  2010-04-02      57258.43       False   \n",
       "3       1    A           1  2010-05-07      17413.94       False   \n",
       "4       1    A           1  2010-06-04      17558.09       False   \n",
       "5       1    A           1  2010-07-02      16333.14       False   \n",
       "6       1    A           1  2010-08-06      17508.41       False   \n",
       "7       1    A           1  2010-09-03      16241.78       False   \n",
       "8       1    A           1  2010-10-01      20094.19       False   \n",
       "9       1    A           1  2010-11-05      34238.88       False   \n",
       "10      1    A           1  2010-12-03      22517.56       False   \n",
       "11      1    A           1  2011-01-07      15984.24       False   \n",
       "\n",
       "    temperature_c  fuel_price_usd_per_l  unemployment  \n",
       "0        5.727778              0.679451         8.106  \n",
       "1        8.055556              0.693452         8.106  \n",
       "2       16.816667              0.718284         7.808  \n",
       "3       22.527778              0.748928         7.808  \n",
       "4       27.050000              0.714586         7.808  \n",
       "5       27.172222              0.705076         7.787  \n",
       "6       30.644444              0.693980         7.787  \n",
       "7       27.338889              0.680772         7.787  \n",
       "8       22.161111              0.687640         7.838  \n",
       "9       14.855556              0.710359         7.838  \n",
       "10       9.594444              0.715378         7.838  \n",
       "11       9.038889              0.786176         7.742  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_1_1 = sales[(sales['department'] == 1) & (sales['store'] == 1)]\n",
    "sales_1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date  weekly_sales  cum_weekly_sales  cum_max_sales\n",
      "0   2010-02-05      24924.50          24924.50       24924.50\n",
      "1   2010-03-05      21827.90          46752.40       24924.50\n",
      "2   2010-04-02      57258.43         104010.83       57258.43\n",
      "3   2010-05-07      17413.94         121424.77       57258.43\n",
      "4   2010-06-04      17558.09         138982.86       57258.43\n",
      "5   2010-07-02      16333.14         155316.00       57258.43\n",
      "6   2010-08-06      17508.41         172824.41       57258.43\n",
      "7   2010-09-03      16241.78         189066.19       57258.43\n",
      "8   2010-10-01      20094.19         209160.38       57258.43\n",
      "9   2010-11-05      34238.88         243399.26       57258.43\n",
      "10  2010-12-03      22517.56         265916.82       57258.43\n",
      "11  2011-01-07      15984.24         281901.06       57258.43\n"
     ]
    }
   ],
   "source": [
    "# Sort sales_1_1 by date\n",
    "sales_1_1 = sales_1_1.sort_values('date')\n",
    "\n",
    "# Get the cumulative sum of weekly_sales, add as cum_weekly_sales col\n",
    "sales_1_1['cum_weekly_sales'] = sales_1_1['weekly_sales'].cumsum()\n",
    "\n",
    "# Get the cumulative max of weekly_sales, add as cum_max_sales col\n",
    "sales_1_1['cum_max_sales'] = sales_1_1['weekly_sales'].cummax()\n",
    "\n",
    "# See the columns you calculated\n",
    "print(sales_1_1[[\"date\", \"weekly_sales\", \"cum_weekly_sales\", \"cum_max_sales\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Dropping duplicates**\n",
    "\n",
    "Removing duplicates is an essential skill to get accurate counts because often, you don't want to count the same thing multiple times. In this exercise, you'll create some new DataFrames using unique values from `sales`.\n",
    "\n",
    "`sales` is available and `pandas` is imported as `pd`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove rows of `sales` with duplicate pairs of `store` and `type` and save as `store_types` and print the head.\n",
    "- Remove rows of `sales` with duplicate pairs of `store` and `department` and save as `store_depts` and print the head.\n",
    "- Subset the rows that are holiday weeks using the `is_holiday` column, and drop the duplicate `date`s, saving as `holiday_dates`.\n",
    "- Select the `date` column of `holiday_dates`, and print."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      store type  department        date  weekly_sales  is_holiday  \\\n",
      "0         1    A           1  2010-02-05      24924.50       False   \n",
      "901       2    A           1  2010-02-05      35034.06       False   \n",
      "1798      4    A           1  2010-02-05      38724.42       False   \n",
      "2699      6    A           1  2010-02-05      25619.00       False   \n",
      "3593     10    B           1  2010-02-05      40212.84       False   \n",
      "\n",
      "      temperature_c  fuel_price_usd_per_l  unemployment  \n",
      "0          5.727778              0.679451         8.106  \n",
      "901        4.550000              0.679451         8.324  \n",
      "1798       6.533333              0.686319         8.623  \n",
      "2699       4.683333              0.679451         7.259  \n",
      "3593      12.411111              0.782478         9.765  \n",
      "    store type  department        date  weekly_sales  is_holiday  \\\n",
      "0       1    A           1  2010-02-05      24924.50       False   \n",
      "12      1    A           2  2010-02-05      50605.27       False   \n",
      "24      1    A           3  2010-02-05      13740.12       False   \n",
      "36      1    A           4  2010-02-05      39954.04       False   \n",
      "48      1    A           5  2010-02-05      32229.38       False   \n",
      "\n",
      "    temperature_c  fuel_price_usd_per_l  unemployment  \n",
      "0        5.727778              0.679451         8.106  \n",
      "12       5.727778              0.679451         8.106  \n",
      "24       5.727778              0.679451         8.106  \n",
      "36       5.727778              0.679451         8.106  \n",
      "48       5.727778              0.679451         8.106  \n",
      "      store type  department        date  weekly_sales  is_holiday  \\\n",
      "498       1    A          45  2010-09-10         11.47        True   \n",
      "691       1    A          77  2011-11-25       1431.00        True   \n",
      "2315      4    A          47  2010-02-12        498.00        True   \n",
      "6735     19    A          39  2012-09-07         13.41        True   \n",
      "6810     19    A          47  2010-12-31       -449.00        True   \n",
      "6815     19    A          47  2012-02-10         15.00        True   \n",
      "6820     19    A          48  2011-09-09        197.00        True   \n",
      "\n",
      "      temperature_c  fuel_price_usd_per_l  unemployment  \n",
      "498       25.938889              0.677602         7.787  \n",
      "691       15.633333              0.854861         7.866  \n",
      "2315      -1.755556              0.679715         8.623  \n",
      "6735      22.333333              1.076766         8.193  \n",
      "6810      -1.861111              0.881278         8.067  \n",
      "6815       0.338889              1.010723         7.943  \n",
      "6820      20.155556              1.038197         7.806  \n"
     ]
    }
   ],
   "source": [
    "# Drop duplicate store/type combinations\n",
    "store_types = sales.drop_duplicates(subset=['store', 'type'])\n",
    "print(store_types.head())\n",
    "\n",
    "# Drop duplicate store/department combinations\n",
    "store_depts = sales.drop_duplicates(subset=['store', 'department'])\n",
    "print(store_depts.head())\n",
    "\n",
    "# Subset the rows where is_holiday is True and drop duplicate dates\n",
    "holiday_dates = sales[sales['is_holiday']].drop_duplicates('date')\n",
    "\n",
    "# Print date col of holiday_dates\n",
    "print(holiday_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Counting categorical variables**\n",
    "\n",
    "Counting is a great way to get an overview of your data and to spot curiosities that you might not notice otherwise. In this exercise, you'll count the number of each type of store and the number of each department number using the DataFrames you created in the previous exercise:\n",
    "\n",
    "```\n",
    "# Drop duplicate store/type combinations\n",
    "store_types = sales.drop_duplicates(subset=[\"store\", \"type\"])\n",
    "\n",
    "# Drop duplicate store/department combinations\n",
    "store_depts = sales.drop_duplicates(subset=[\"store\", \"department\"])\n",
    "\n",
    "```\n",
    "\n",
    "The `store_types` and `store_depts` DataFrames you created in the last exercise are available, and `pandas`is imported as `pd`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the number of stores of each store type in store_types.\n",
    "Count the proportion of stores of each store type in store_types.\n",
    "Count the number of different departments in store_depts, sorting the counts in descending order.\n",
    "Count the proportion of different departments in store_depts, sorting the proportions in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>type</th>\n",
       "      <th>department</th>\n",
       "      <th>date</th>\n",
       "      <th>weekly_sales</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>temperature_c</th>\n",
       "      <th>fuel_price_usd_per_l</th>\n",
       "      <th>unemployment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>24924.50</td>\n",
       "      <td>False</td>\n",
       "      <td>5.727778</td>\n",
       "      <td>0.679451</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>35034.06</td>\n",
       "      <td>False</td>\n",
       "      <td>4.550000</td>\n",
       "      <td>0.679451</td>\n",
       "      <td>8.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>38724.42</td>\n",
       "      <td>False</td>\n",
       "      <td>6.533333</td>\n",
       "      <td>0.686319</td>\n",
       "      <td>8.623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2699</th>\n",
       "      <td>6</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>25619.00</td>\n",
       "      <td>False</td>\n",
       "      <td>4.683333</td>\n",
       "      <td>0.679451</td>\n",
       "      <td>7.259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3593</th>\n",
       "      <td>10</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>40212.84</td>\n",
       "      <td>False</td>\n",
       "      <td>12.411111</td>\n",
       "      <td>0.782478</td>\n",
       "      <td>9.765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4495</th>\n",
       "      <td>13</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>46761.90</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.261111</td>\n",
       "      <td>0.704283</td>\n",
       "      <td>8.316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5408</th>\n",
       "      <td>14</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>32842.31</td>\n",
       "      <td>False</td>\n",
       "      <td>-2.605556</td>\n",
       "      <td>0.735455</td>\n",
       "      <td>8.992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6293</th>\n",
       "      <td>19</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>21500.58</td>\n",
       "      <td>False</td>\n",
       "      <td>-6.133333</td>\n",
       "      <td>0.780365</td>\n",
       "      <td>8.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7199</th>\n",
       "      <td>20</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>46021.21</td>\n",
       "      <td>False</td>\n",
       "      <td>-3.377778</td>\n",
       "      <td>0.735455</td>\n",
       "      <td>8.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8109</th>\n",
       "      <td>27</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>32313.79</td>\n",
       "      <td>False</td>\n",
       "      <td>-2.672222</td>\n",
       "      <td>0.780365</td>\n",
       "      <td>8.237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9009</th>\n",
       "      <td>31</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>18187.71</td>\n",
       "      <td>False</td>\n",
       "      <td>3.916667</td>\n",
       "      <td>0.679451</td>\n",
       "      <td>8.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9899</th>\n",
       "      <td>39</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>21244.50</td>\n",
       "      <td>False</td>\n",
       "      <td>6.833333</td>\n",
       "      <td>0.679451</td>\n",
       "      <td>8.554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      store type  department        date  weekly_sales  is_holiday  \\\n",
       "0         1    A           1  2010-02-05      24924.50       False   \n",
       "901       2    A           1  2010-02-05      35034.06       False   \n",
       "1798      4    A           1  2010-02-05      38724.42       False   \n",
       "2699      6    A           1  2010-02-05      25619.00       False   \n",
       "3593     10    B           1  2010-02-05      40212.84       False   \n",
       "4495     13    A           1  2010-02-05      46761.90       False   \n",
       "5408     14    A           1  2010-02-05      32842.31       False   \n",
       "6293     19    A           1  2010-02-05      21500.58       False   \n",
       "7199     20    A           1  2010-02-05      46021.21       False   \n",
       "8109     27    A           1  2010-02-05      32313.79       False   \n",
       "9009     31    A           1  2010-02-05      18187.71       False   \n",
       "9899     39    A           1  2010-02-05      21244.50       False   \n",
       "\n",
       "      temperature_c  fuel_price_usd_per_l  unemployment  \n",
       "0          5.727778              0.679451         8.106  \n",
       "901        4.550000              0.679451         8.324  \n",
       "1798       6.533333              0.686319         8.623  \n",
       "2699       4.683333              0.679451         7.259  \n",
       "3593      12.411111              0.782478         9.765  \n",
       "4495      -0.261111              0.704283         8.316  \n",
       "5408      -2.605556              0.735455         8.992  \n",
       "6293      -6.133333              0.780365         8.350  \n",
       "7199      -3.377778              0.735455         8.187  \n",
       "8109      -2.672222              0.780365         8.237  \n",
       "9009       3.916667              0.679451         8.324  \n",
       "9899       6.833333              0.679451         8.554  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type\n",
      "A    11\n",
      "B     1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of stores of each type\n",
    "store_counts = store_types['type'].value_counts()\n",
    "print(store_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type\n",
      "A    0.916667\n",
      "B    0.083333\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Get the proportion of stores of each type\n",
    "store_props = store_types['type'].value_counts(normalize=True)\n",
    "print(store_props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "department\n",
      "1     12\n",
      "55    12\n",
      "72    12\n",
      "71    12\n",
      "67    12\n",
      "      ..\n",
      "37    10\n",
      "48     8\n",
      "50     6\n",
      "39     4\n",
      "43     2\n",
      "Name: count, Length: 80, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of each department number and sort\n",
    "dept_counts_sorted = store_depts['department'].value_counts(sort=True)\n",
    "print(dept_counts_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "department\n",
      "1     0.012917\n",
      "55    0.012917\n",
      "72    0.012917\n",
      "71    0.012917\n",
      "67    0.012917\n",
      "        ...   \n",
      "37    0.010764\n",
      "48    0.008611\n",
      "50    0.006459\n",
      "39    0.004306\n",
      "43    0.002153\n",
      "Name: proportion, Length: 80, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Get the proportion of departments of each number and sort\n",
    "dept_props_sorted = store_depts['department'].value_counts(sort=True, normalize=True)\n",
    "print(dept_props_sorted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcd-projectsI2025a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
